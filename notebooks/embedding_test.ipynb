{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "238434a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from typing import List, Dict\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bdea7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Generic HF CLS Embedder\n",
    "# ===============================\n",
    "class HFCLSEmbedder:\n",
    "    def __init__(self, model_path: str, device: str = 'cpu'):\n",
    "        model_path = str(Path(model_path).resolve())\n",
    "        self.model_path = model_path\n",
    "        self.device = device\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path,\n",
    "            local_files_only=True\n",
    "        )\n",
    "\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            model_path,\n",
    "            local_files_only=True\n",
    "        ).to(device)\n",
    "\n",
    "        self.model.eval()\n",
    "\n",
    "    def encode(self, texts: List[str]) -> np.ndarray:\n",
    "        with torch.no_grad():\n",
    "            inputs = self.tokenizer(\n",
    "                texts,\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            outputs = self.model(**inputs)\n",
    "\n",
    "            # CLS token embedding\n",
    "            cls_embeddings = outputs.last_hidden_state[:, 0]\n",
    "\n",
    "            # Normalize for cosine similarity\n",
    "            cls_embeddings = F.normalize(cls_embeddings, dim=1)\n",
    "\n",
    "            return cls_embeddings.cpu().numpy()\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# Cosine similarity\n",
    "# ===============================\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> float:\n",
    "    return float(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4d5147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# Load all models ONCE\n",
    "# ===============================\n",
    "def load_embedders(models: Dict[str, str]) -> Dict[str, HFCLSEmbedder]:\n",
    "    embedders = {}\n",
    "\n",
    "    for name, model_path in models.items():\n",
    "        print(f\"\\nğŸ” Loading {name} ...\")\n",
    "        embedders[name] = HFCLSEmbedder(model_path)\n",
    "\n",
    "    return embedders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98fa9318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Loading PubMedBERT ...\n",
      "\n",
      "ğŸ” Loading ClinicalBERT ...\n",
      "\n",
      "ğŸ” Loading BioELECTRA ...\n",
      "\n",
      "ğŸ” Loading SapBERT ...\n",
      "\n",
      "ğŸ” Loading BioBERT ...\n",
      "\n",
      "ğŸ” Loading MiniLM-L6 ...\n",
      "\n",
      "ğŸ“Š Benchmarking PubMedBERT ...\n",
      "\n",
      "ğŸ“Š Benchmarking ClinicalBERT ...\n",
      "\n",
      "ğŸ“Š Benchmarking BioELECTRA ...\n",
      "\n",
      "ğŸ“Š Benchmarking SapBERT ...\n",
      "\n",
      "ğŸ“Š Benchmarking BioBERT ...\n",
      "\n",
      "ğŸ“Š Benchmarking MiniLM-L6 ...\n",
      "\n",
      "================= RESULTS =================\n",
      "\n",
      "ğŸ§  PubMedBERT\n",
      "  Mean similarity: 0.9567\n",
      "  Min similarity : 0.9120\n",
      "  Max similarity : 0.9852\n",
      "\n",
      "ğŸ§  ClinicalBERT\n",
      "  Mean similarity: 0.9142\n",
      "  Min similarity : 0.8315\n",
      "  Max similarity : 0.9467\n",
      "\n",
      "ğŸ§  BioELECTRA\n",
      "  Mean similarity: 0.9478\n",
      "  Min similarity : 0.9202\n",
      "  Max similarity : 0.9706\n",
      "\n",
      "ğŸ§  SapBERT\n",
      "  Mean similarity: 0.7310\n",
      "  Min similarity : 0.2902\n",
      "  Max similarity : 0.9113\n",
      "\n",
      "ğŸ§  BioBERT\n",
      "  Mean similarity: 0.7216\n",
      "  Min similarity : 0.2975\n",
      "  Max similarity : 0.8874\n",
      "\n",
      "ğŸ§  MiniLM-L6\n",
      "  Mean similarity: 0.8129\n",
      "  Min similarity : 0.4990\n",
      "  Max similarity : 0.9578\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# Benchmark runner\n",
    "# ===============================\n",
    "def benchmark_similarity(\n",
    "    embedders: Dict[str, HFCLSEmbedder],\n",
    "    text_pairs: List[List[str]]\n",
    "):\n",
    "    results = {}\n",
    "\n",
    "    for name, embedder in embedders.items():\n",
    "        print(f\"\\nğŸ“Š Benchmarking {name} ...\")\n",
    "\n",
    "        scores = []\n",
    "        for t1, t2 in text_pairs:\n",
    "            emb = embedder.encode([t1, t2])\n",
    "            sim = cosine_sim(emb[0], emb[1])\n",
    "            scores.append(sim)\n",
    "\n",
    "        results[name] = {\n",
    "            \"mean_similarity\": float(np.mean(scores)),\n",
    "            \"min\": float(np.min(scores)),\n",
    "            \"max\": float(np.max(scores)),\n",
    "            \"scores\": scores,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# MAIN\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    TEXT_PAIRS = [\n",
    "        (\n",
    "            \"Heart rate variability reflects autonomic nervous system function.\",\n",
    "            \"HRV is an indicator of autonomic nervous system activity.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Poor sleep quality increases cardiovascular risk.\",\n",
    "            \"Lack of sleep is associated with higher risk of heart disease.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Vitamin D deficiency affects bone health.\",\n",
    "            \"Vitamin D is essential for maintaining bone density.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Insulin regulates blood glucose levels.\",\n",
    "            \"Blood sugar is controlled by insulin.\"\n",
    "        ),\n",
    "        (\n",
    "            \"Heart rate variability reflects autonomic nervous system function.\",\n",
    "            \"Vitamin D is essential for bone health.\"\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    MODELS = {\n",
    "        \"PubMedBERT\": \"./models/pubmedbert\",\n",
    "        \"ClinicalBERT\": \"./models/clinicalbert\",\n",
    "        \"BioELECTRA\": \"./models/bioelectra\",\n",
    "        \"SapBERT\": \"./models/sapbert\",\n",
    "        \"BioBERT\": \"./models/biobert-stsb\",\n",
    "        \"MiniLM-L6\": \"./models/all-MiniLM-L6-v2\",\n",
    "    }\n",
    "\n",
    "    embedders = load_embedders(MODELS)\n",
    "    results = benchmark_similarity(embedders, TEXT_PAIRS)\n",
    "\n",
    "    print(\"\\n================= RESULTS =================\")\n",
    "    for model, stats in results.items():\n",
    "        print(f\"\\nğŸ§  {model}\")\n",
    "        print(f\"  Mean similarity: {stats['mean_similarity']:.4f}\")\n",
    "        print(f\"  Min similarity : {stats['min']:.4f}\")\n",
    "        print(f\"  Max similarity : {stats['max']:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
